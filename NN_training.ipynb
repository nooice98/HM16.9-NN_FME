{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Proess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports & Global variables list:**  \n",
    "A symbolic link is done to import FastAI v0.7 library, the target folder is named \"fastai07\"  \n",
    "\n",
    "NAME: nickname for our model, must match the folder name in DL folder  \n",
    "INP: Directory where we will read our input file  \n",
    "DIR: Directory where we'll save model and export our parameters  \n",
    "cat_vars: List of categorical variables in our model  \n",
    "cont_vars: List of continous variables in our model  \n",
    "QP: Quantization Parameter  \n",
    "Layers: Number of neurons per hidden layer in our network  \n",
    "Dropouts: Percentage of dropout rate per hidden layer  \n",
    "BN_use: Use batch normalization if set to True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai07.structured import *\n",
    "from fastai07.column_data import *\n",
    "\n",
    "NAME='blowing40'\n",
    "INP='./DL'\n",
    "DIR='./DL/{0}'.format(NAME)\n",
    "cat_vars = ['Height', 'Width']\n",
    "cont_vars = ['top_left', 'top_center', 'top_right', 'left', 'center', 'right', \n",
    "             'bottom_left', 'bottom_center', 'bottom_right']\n",
    "maplist = [['top_left', 0], ['top_center', 1], ['top_right', 2], ['left', 3], ['center', 4], ['right', 5], \n",
    "         ['bottom_left', 6], ['bottom_center', 7], ['bottom_right', 8]]\n",
    "QP=22\n",
    "Layers=[40, 40, 40]\n",
    "Dropouts=[0.001, 0.001, 0.01]\n",
    "BN_use=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**:  \n",
    "In FastAI v0.7, there's a proc_df() function that does the following:  \n",
    "1) Splits dependent variable \"output\" from the dataframe  \n",
    "2) Normalizes the continuous variables  \n",
    "3) Returns a mapper that holds the mean and std for normalization  \n",
    "4) Categorizes the categorical variables  \n",
    "5) Handles missing values  \n",
    "\n",
    "This function will be used in read_proc() process our data. Note that we don't have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read, normalize, and process Inputs and Outputs\n",
    "def read_proc():\n",
    "    df = pd.read_csv('{0}/SSE_{1}.csv'.format(INP, QP), names=cont_vars+cat_vars+['y'])\n",
    "    for v in cat_vars: df[v] = df[v].astype('category').cat.as_ordered()\n",
    "    for v in cont_vars: df[v] = df[v].astype('float32')\n",
    "    df, y, nas, mapper = proc_df(df, 'y',do_scale=True)\n",
    "    del nas\n",
    "    for v in cat_vars: df[v] = df[v].astype('category').cat.as_ordered()\n",
    "    for v in cont_vars: df[v] = df[v].astype('float32')\n",
    "    cat_sz = [(c, len(df[c].cat.categories)+1) for c in cat_vars]\n",
    "    # Rule of Thumb for embedding sizes \"taken from FastAI course 2018\"\n",
    "    emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]\n",
    "    val_idx = get_cv_idxs(len(df), val_pct=0.2)\n",
    "    return df, y, mapper, emb_szs, val_idx\n",
    "\n",
    "# Export the Mean and STDev\n",
    "# The target folder is: ./$DIR/$QP/\n",
    "def export_mapper():\n",
    "    mapper_df = pd.DataFrame(index=['mean', 'std'], columns=cont_vars)\n",
    "    for column,i in maplist:\n",
    "        mapper_df[column].loc['mean'] = np.float64(mapper.features[i][1].mean_)\n",
    "        mapper_df[column].loc['std'] = np.float64(np.sqrt(mapper.features[i][1].var_))\n",
    "\n",
    "    mapper_df.to_csv('{0}/{1}/mapper_{1}.csv'.format(DIR, QP), index=False, header=None, line_terminator=\";\\n\")\n",
    "    return\n",
    "\n",
    "# Process and Save model\n",
    "# The saved model is in the format: QP{qp}_{name}_{accuracy}\n",
    "def save_model():\n",
    "    log_preds, targs = m.predict_with_targs()\n",
    "    preds = np.argmax(log_preds, axis=1)\n",
    "    right = 0\n",
    "    for i in range (len(preds)):\n",
    "        if(preds[i] == targs[i]):\n",
    "            right += 1\n",
    "    acc = (right / len(preds)) * 100\n",
    "    print(\"Validation accuracy: \", acc)\n",
    "    name = \"QP{0}_{1}_acc{2}\".format(QP, NAME, round(acc, 2))\n",
    "    m.save(name)\n",
    "    return\n",
    "\n",
    "# Export Weights and Biases for each layer\n",
    "# The target folder is: ./$DIR/$QP/\n",
    "def export_parameters():\n",
    "    for i in range(len(m.model.bns)):\n",
    "        pd.DataFrame(m.model.bns[i].weight.data.numpy()).to_csv('{0}/{1}/bns{2}-weight.csv'.format(DIR, QP, i), \n",
    "                                                                index=False, header=None , line_terminator=\", \")\n",
    "        pd.DataFrame(m.model.bns[i].bias.data.numpy()).to_csv('{0}/{1}/bns{2}-bias.csv'.format(DIR, QP, i), \n",
    "                                                              index=False, header=None , line_terminator=\", \")\n",
    "    for i in range(len(m.model.lins)):\n",
    "        pd.DataFrame(m.model.lins[i].weight.data.numpy()).to_csv('{0}/{1}/lins{2}-weight.csv'.format(DIR, QP, i), \n",
    "                                                                 index=False, header=None, line_terminator=\",\\n\")\n",
    "        pd.DataFrame(m.model.lins[i].bias.data.numpy()).to_csv('{0}/{1}/lins{2}-bias.csv'.format(DIR, QP, i), \n",
    "                                                               index=False, header=None, line_terminator=\", \")\n",
    "    for i in range(len(m.model.embs)):\n",
    "        pd.DataFrame(m.model.embs[i].weight.data.numpy()).to_csv('{0}/{1}/emb{2}-weight.csv'.format(DIR, QP, i), \n",
    "                                                                index=False, header=None, line_terminator=\",\\n\")\n",
    "    pd.DataFrame(m.model.outp.weight.data.numpy()).to_csv('{0}/{1}/outp-weight.csv'.format(DIR, QP), \n",
    "                                                          index=False, header=None, line_terminator=\",\\n\")\n",
    "    pd.DataFrame(m.model.outp.bias.data.numpy()).to_csv('{0}/{1}/outp-bias.csv'.format(DIR, QP), index=False, \n",
    "                                                        header=None, line_terminator=\", \")\n",
    "    pd.DataFrame(m.model.bn.weight.data.numpy()).to_csv('{0}/{1}/bn-weight.csv'.format(DIR, QP), index=False, \n",
    "                                                        header=None, line_terminator=\", \")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read and process our input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in globals(): del df, y, mapper\n",
    "df, y, mapper, emb_szs, val_idx = read_proc()\n",
    "# Optional: export mapper for inference\n",
    "export_mapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ModelData and Learner objects  \n",
    "The problem we're dealing with is a multi-class classification \"output is one of 49 fractional locations\", so in get_learner() function, we set is_multi= and is_reg= to False  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(INP, val_idx, df, y, cat_flds=cat_vars, \n",
    "                                       bs=1024, is_multi=False, is_reg=False)\n",
    "m = md.get_learner(emb_szs, len(df.columns) - len(cat_vars),\n",
    "                   0.001, 49, Layers, Dropouts, use_bn=BN_use)\n",
    "# Optional: Load previously saved model\n",
    "# m.load('QP22_blowing_200_train_acc36.51')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run learning Rate Finder:  \n",
    "Plots the error for each learning rate, we choose the learning rate before the error starts flattening out \"in our case, usually learning rate = 1e-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81de352265064102831d3b43b8e6cea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 13481/17810 [03:46<00:56, 77.07it/s, loss=5]   "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.lr_find()\n",
    "m.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model for a specified number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8731abda1a0a48e79c1718ee39f9e2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      2.117737   2.152133   0.34648   \n",
      "    1      2.048123   2.028033   0.374526                       \n",
      "    2      2.018874   2.005237   0.379534                       \n",
      "    3      2.000444   2.003024   0.381075                       \n",
      "    4      1.982402   2.006863   0.379584                       \n",
      "    5      1.968877   1.958874   0.390146                       \n",
      "    6      1.970172   1.946487   0.391562                       \n",
      "    7      1.949199   1.935375   0.396452                       \n",
      "    8      1.949004   1.928752   0.398033                       \n",
      "    9      1.950622   1.913924   0.401026                       \n",
      "    10     1.934265   1.918122   0.400099                       \n",
      "    11     1.934632   1.917151   0.399896                       \n",
      "    12     1.920567   1.936577   0.397982                       \n",
      "    13     1.925818   1.941644   0.395689                       \n",
      "    14     1.93092    1.930465   0.397425                       \n",
      "    15     1.92941    1.913212   0.401006                       \n",
      "    16     1.923975   1.905478   0.402512                       \n",
      "    17     1.92408    1.89525    0.405425                       \n",
      "    18     1.921915   1.916776   0.401699                       \n",
      "    19     1.910961   1.911578   0.4021                         \n",
      "    20     1.90852    1.929462   0.39916                        \n",
      "    21     1.923162   1.91371    0.401116                       \n",
      "    22     1.910136   1.900194   0.40428                        \n",
      "    23     1.906921   1.901352   0.403051                       \n",
      "    24     1.910774   1.896631   0.405641                       \n",
      "    25     1.908584   1.918083   0.401396                       \n",
      "    26     1.913447   1.890416   0.408022                       \n",
      "    27     1.912767   1.964585   0.387366                       \n",
      "    28     1.913481   1.898305   0.404652                       \n",
      "    29     1.912508   1.883904   0.408021                       \n",
      "    30     1.900135   1.892627   0.406729                       \n",
      "    31     1.909079   1.889539   0.407276                       \n",
      "    32     1.897388   1.902749   0.404994                       \n",
      "    33     1.908966   1.895637   0.406534                       \n",
      "    34     1.910927   1.908068   0.403315                       \n",
      "    35     1.90797    1.884916   0.407359                       \n",
      "    36     1.89449    1.902661   0.40442                        \n",
      "    37     1.905317   1.894683   0.406606                       \n",
      "    38     1.895925   1.889269   0.40743                        \n",
      "    39     1.911235   1.90145    0.405706                       \n",
      "    40     1.899055   1.891282   0.407377                       \n",
      "    41     1.905473   1.892592   0.405666                       \n",
      "    42     1.900469   1.900546   0.405336                       \n",
      "    43     1.901874   1.907032   0.403331                       \n",
      "    44     1.892635   1.887736   0.407078                       \n",
      "    45     1.898182   1.877089   0.409781                       \n",
      "    46     1.890539   1.881603   0.407935                       \n",
      "    47     1.892804   1.894929   0.405025                       \n",
      "    48     1.904086   1.931724   0.393889                       \n",
      "    49     1.890717   1.891305   0.406369                       \n",
      "    50     1.897849   1.880703   0.408263                       \n",
      "    51     1.893997   1.886943   0.407713                       \n",
      "    52     1.898101   1.889195   0.406721                       \n",
      "    53     1.898084   1.878317   0.409315                       \n",
      "    54     1.890569   1.938277   0.401753                       \n",
      "    55     1.88743    1.890273   0.407874                       \n",
      "    56     1.885596   1.89972    0.405584                       \n",
      "    57     1.886357   1.891341   0.406034                       \n",
      "    58     1.894375   1.875815   0.409101                       \n",
      "    59     1.8892     1.902172   0.403967                       \n",
      "    60     1.89257    1.886384   0.408056                       \n",
      "    61     1.885464   1.8802     0.409411                       \n",
      "    62     1.885336   1.878537   0.409135                       \n",
      "    63     1.888355   1.946662   0.396221                       \n",
      "    64     1.89079    1.874318   0.410756                       \n",
      "    65     1.894242   1.877653   0.410226                       \n",
      "    66     1.892827   1.890141   0.407441                       \n",
      "    67     1.887976   1.880953   0.409147                       \n",
      "    68     1.887346   1.875786   0.410195                       \n",
      "    69     1.884496   1.908856   0.402295                       \n",
      "    70     1.895285   1.91254    0.401573                       \n",
      "    71     1.888522   1.898997   0.406268                       \n",
      "    72     1.892639   1.872042   0.411411                       \n",
      "    73     1.887233   1.886802   0.40844                        \n",
      "    74     1.888567   1.878638   0.410357                       \n",
      "    75     1.890468   1.871577   0.410417                       \n",
      "    76     1.890607   1.879375   0.410479                       \n",
      "    77     1.881111   1.872742   0.411262                       \n",
      "    78     1.889671   1.896944   0.40708                        \n",
      "    79     1.894564   1.86984    0.412103                       \n",
      "    80     1.882353   1.916074   0.403681                       \n",
      "    81     1.891137   1.870814   0.410997                       \n",
      "    82     1.883038   1.876142   0.410227                       \n",
      "    83     1.892587   1.870716   0.412325                       \n",
      "    84     1.883055   1.881779   0.4088                         \n",
      "    85     1.88746    1.889974   0.406224                       \n",
      "    86     1.892769   1.878481   0.410147                       \n",
      "    87     1.878714   1.887351   0.409321                       \n",
      "    88     1.887652   1.882797   0.409563                       \n",
      "    89     1.889564   1.877206   0.410201                       \n",
      "    90     1.882009   1.878557   0.409707                       \n",
      "    91     1.893954   1.87058    0.411616                       \n",
      "    92     1.891629   1.876152   0.411344                       \n",
      "    93     1.883061   1.866919   0.412218                       \n",
      "    94     1.887601   1.880788   0.409373                       \n",
      "    95     1.87359    1.879635   0.410206                       \n",
      "    96     1.881149   1.868487   0.41248                        \n",
      "    97     1.890224   1.905479   0.403589                       \n",
      "    98     1.882929   1.878208   0.410472                       \n",
      "    99     1.878418   1.869121   0.412711                       \n",
      "   100     1.87491    1.867228   0.412077                       \n",
      "   101     1.884703   1.867276   0.412659                       \n",
      "   102     1.886818   1.87795    0.409931                       \n",
      "   103     1.882486   1.874463   0.410769                       \n",
      "   104     1.870836   1.878848   0.409555                       \n",
      "   105     1.886284   1.90373    0.403632                       \n",
      "   106     1.885876   1.867686   0.412101                       \n",
      "   107     1.888735   1.877386   0.409478                       \n",
      "   108     1.877575   1.908644   0.404773                       \n",
      "   109     1.882387   1.865467   0.412731                       \n",
      "   110     1.884964   1.871423   0.411639                       \n",
      "   111     1.883025   1.866211   0.413137                       \n",
      "   112     1.884677   1.878651   0.410509                       \n",
      "   113     1.87945    1.880271   0.409864                       \n",
      "   114     1.886031   1.873596   0.411627                       \n",
      "   115     1.882113   1.894275   0.40698                        \n",
      "   116     1.88262    1.8628     0.413008                       \n",
      "   117     1.876466   1.871383   0.411536                       \n",
      "   118     1.878623   1.863809   0.413076                       \n",
      "   119     1.885004   1.8662     0.412635                       \n",
      "   120     1.883835   1.866979   0.412114                       \n",
      "   121     1.880643   1.870774   0.411766                       \n",
      "   122     1.877326   1.876882   0.410224                       \n",
      "   123     1.880631   1.866932   0.412033                       \n",
      "   124     1.875129   1.864676   0.413405                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   125     1.884884   1.880651   0.40995                        \n",
      "   126     1.876901   1.870684   0.411431                       \n",
      "   127     1.884332   1.876803   0.411085                       \n",
      "   128     1.874243   1.880433   0.410614                       \n",
      "   129     1.876269   1.889186   0.40811                        \n",
      "   130     1.877369   1.887386   0.408224                       \n",
      "   131     1.882632   1.864274   0.41291                        \n",
      "   132     1.885277   1.876055   0.411525                       \n",
      "   133     1.876771   1.893178   0.407825                       \n",
      "   134     1.877735   1.866479   0.413244                       \n",
      "   135     1.87916    1.880612   0.409586                       \n",
      "   136     1.878015   1.884054   0.409943                       \n",
      "   137     1.878218   1.881083   0.409041                       \n",
      "   138     1.879352   1.885184   0.408856                       \n",
      "   139     1.88823    1.86717    0.412381                       \n",
      "   140     1.878531   1.871691   0.411892                       \n",
      "   141     1.887282   1.871935   0.411352                       \n",
      "   142     1.877596   1.87161    0.411536                       \n",
      "   143     1.87646    1.867011   0.412516                       \n",
      "   144     1.885243   1.864507   0.41266                        \n",
      "   145     1.877862   1.864639   0.413422                       \n",
      "   146     1.878017   1.865589   0.413037                       \n",
      "   147     1.887951   1.873084   0.410531                       \n",
      "   148     1.87406    1.865514   0.413494                       \n",
      "   149     1.882544   1.871997   0.411139                       \n",
      "   150     1.87716    1.871676   0.412253                       \n",
      "   151     1.878161   1.870679   0.41196                        \n",
      "   152     1.877821   1.869723   0.4118                         \n",
      "   153     1.885671   1.865421   0.413107                       \n",
      "   154     1.871876   1.871306   0.411412                       \n",
      "   155     1.877568   1.868149   0.412419                       \n",
      "   156     1.877438   1.867204   0.413065                       \n",
      "   157     1.864776   1.862824   0.412877                       \n",
      "   158     1.883662   1.876888   0.411401                       \n",
      "   159     1.875464   1.856889   0.414945                       \n",
      "   160     1.888917   1.875236   0.411185                       \n",
      "   161     1.877614   1.862938   0.413024                       \n",
      "   162     1.870942   1.861156   0.413992                       \n",
      "   163     1.879757   1.877079   0.410088                       \n",
      "   164     1.879538   1.8785     0.410509                       \n",
      "   165     1.882918   1.872734   0.412337                       \n",
      "   166     1.870189   1.870755   0.412119                       \n",
      "   167     1.883948   1.863041   0.413503                       \n",
      "   168     1.883695   1.864249   0.41275                        \n",
      "   169     1.877083   1.882799   0.411163                       \n",
      "   170     1.876998   1.863956   0.413341                       \n",
      "   171     1.870328   1.865194   0.412666                       \n",
      "   172     1.875958   1.864968   0.412323                       \n",
      "   173     1.878725   1.873874   0.410364                       \n",
      "   174     1.889911   1.869997   0.411339                       \n",
      "   175     1.879044   1.865539   0.41276                        \n",
      "   176     1.871553   1.864328   0.412918                       \n",
      "   177     1.881309   1.869838   0.412116                       \n",
      "   178     1.872994   1.86244    0.413342                       \n",
      "   179     1.876697   1.860619   0.413879                       \n",
      "   180     1.875347   1.865376   0.412583                       \n",
      "   181     1.870239   1.864878   0.412287                       \n",
      "   182     1.873815   1.859055   0.413589                       \n",
      "   183     1.883455   1.873274   0.411705                       \n",
      "   184     1.876275   1.864481   0.41292                        \n",
      "   185     1.877358   1.858362   0.414468                       \n",
      "   186     1.876596   1.862412   0.413274                       \n",
      "   187     1.870485   1.859277   0.414103                       \n",
      "   188     1.877529   1.861502   0.414147                       \n",
      "   189     1.871994   1.86144    0.413434                       \n",
      "   190     1.874232   1.869967   0.412341                       \n",
      "   191     1.869784   1.862805   0.413433                       \n",
      "   192     1.878092   1.858119   0.414369                       \n",
      "   193     1.873848   1.868909   0.412145                       \n",
      "   194     1.881856   1.872913   0.411236                       \n",
      "   195     1.880007   1.86506    0.41325                        \n",
      "   196     1.874648   1.869978   0.411691                       \n",
      "   197     1.874508   1.871402   0.411029                       \n",
      "   198     1.867661   1.877113   0.410324                       \n",
      "   199     1.878125   1.87789    0.410668                       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.87789]), 0.41066789145933036]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = 1e-3\n",
    "m.fit(LR, 200, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and Export parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  41.066789145933036\n"
     ]
    }
   ],
   "source": [
    "save_model()\n",
    "export_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for other Quantization Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a90088160849138eb8430264ae71a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      2.251285   2.230246   0.336212  \n",
      "    1      2.185188   2.177998   0.346334                       \n",
      "    2      2.167491   2.161156   0.350222                       \n",
      "    3      2.162263   2.142226   0.354434                       \n",
      "    4      2.149573   2.138094   0.357433                       \n",
      "    5      2.142468   2.128669   0.357327                       \n",
      "    6      2.140623   2.125181   0.359065                       \n",
      "    7      2.134553   2.117276   0.360753                       \n",
      "    8      2.134821   2.119755   0.359928                       \n",
      "    9      2.138445   2.1268     0.35925                        \n",
      "    10     2.123118   2.129384   0.358773                       \n",
      "    11     2.122763   2.137295   0.357884                       \n",
      "    12     2.119404   2.105574   0.362864                       \n",
      "    13     2.128693   2.106975   0.362118                       \n",
      "    14     2.126564   2.111793   0.360813                       \n",
      "    15     2.121079   2.116349   0.360623                       \n",
      "    16     2.114475   2.103707   0.363409                       \n",
      "    17     2.11732    2.112221   0.36126                        \n",
      "    18     2.121272   2.108268   0.362586                       \n",
      "    19     2.125808   2.109076   0.361976                       \n",
      "    20     2.120704   2.104628   0.363193                       \n",
      "    21     2.120303   2.106933   0.362752                       \n",
      "    22     2.123594   2.105957   0.362745                       \n",
      "    23     2.116716   2.103071   0.362932                       \n",
      "    24     2.116394   2.101206   0.363526                       \n",
      "    25     2.117956   2.106994   0.363109                       \n",
      "    26     2.1127     2.099064   0.364277                       \n",
      "    27     2.117548   2.103035   0.364224                       \n",
      "    28     2.119482   2.103546   0.364276                       \n",
      "    29     2.115968   2.102294   0.362756                       \n",
      "    30     2.107973   2.109999   0.362844                       \n",
      "    31     2.109087   2.10547    0.362362                       \n",
      "    32     2.114043   2.096932   0.364739                       \n",
      "    33     2.110389   2.097153   0.3646                         \n",
      "    34     2.119869   2.095906   0.364529                       \n",
      "    35     2.112084   2.101132   0.364274                       \n",
      "    36     2.113995   2.095078   0.365115                       \n",
      "    37     2.11624    2.104008   0.36334                        \n",
      "    38     2.11801    2.092398   0.365722                       \n",
      "    39     2.108441   2.093215   0.366356                       \n",
      "    40     2.116863   2.097187   0.365119                       \n",
      "    41     2.104109   2.096736   0.365036                       \n",
      "    42     2.098299   2.107809   0.362867                       \n",
      "    43     2.111513   2.097721   0.36466                        \n",
      "    44     2.105631   2.091748   0.365732                       \n",
      "    45     2.111911   2.104053   0.364006                       \n",
      "    46     2.104646   2.09562    0.365366                       \n",
      "    47     2.100375   2.096121   0.364217                       \n",
      "    48     2.106027   2.08948    0.366137                       \n",
      "    49     2.107636   2.097629   0.365116                       \n",
      "    50     2.103245   2.099059   0.364329                       \n",
      "    51     2.105385   2.085047   0.366663                       \n",
      "    52     2.105055   2.096557   0.365012                       \n",
      "    53     2.099261   2.085453   0.366444                       \n",
      "    54     2.110336   2.092991   0.365859                       \n",
      "    55     2.108582   2.093719   0.365125                       \n",
      "    56     2.10217    2.089077   0.366367                       \n",
      "    57     2.114238   2.093278   0.3665                         \n",
      "    58     2.10455    2.087949   0.366651                       \n",
      "    59     2.106715   2.08925    0.366277                       \n",
      "    60     2.09958    2.088627   0.366439                       \n",
      "    61     2.09441    2.090682   0.366294                       \n",
      "    62     2.110353   2.111494   0.363526                       \n",
      "    63     2.108319   2.097051   0.365696                       \n",
      "    64     2.103086   2.097159   0.36557                        \n",
      "    65     2.100729   2.086831   0.366939                       \n",
      "    66     2.103671   2.088532   0.366267                       \n",
      "    67     2.088863   2.086651   0.366416                       \n",
      "    68     2.100711   2.094323   0.366163                       \n",
      "    69     2.101053   2.101597   0.364391                       \n",
      "    70     2.093473   2.088246   0.366699                       \n",
      "    71     2.100853   2.089324   0.365714                       \n",
      "    72     2.10416    2.087644   0.367181                       \n",
      "    73     2.100424   2.092298   0.366492                       \n",
      "    74     2.091433   2.083778   0.367422                       \n",
      "    75     2.10739    2.087517   0.366866                       \n",
      "    76     2.102359   2.085819   0.366735                       \n",
      "    77     2.107205   2.091432   0.366025                       \n",
      "    78     2.107292   2.084513   0.367782                       \n",
      "    79     2.107321   2.085527   0.367194                       \n",
      "    80     2.094147   2.083641   0.367707                       \n",
      "    81     2.102163   2.08485    0.36739                        \n",
      "    82     2.104444   2.09366    0.365494                       \n",
      "    83     2.09453    2.099814   0.365062                       \n",
      "    84     2.095176   2.08778    0.366308                       \n",
      "    85     2.103713   2.082452   0.367254                       \n",
      "    86     2.095123   2.083805   0.367542                       \n",
      "    87     2.092297   2.086485   0.366789                       \n",
      "    88     2.105715   2.090482   0.366233                       \n",
      "    89     2.10139    2.083306   0.367733                       \n",
      "    90     2.105295   2.090855   0.365954                       \n",
      "    91     2.097843   2.086355   0.366449                       \n",
      "    92     2.107176   2.094184   0.365843                       \n",
      "    93     2.099709   2.089102   0.366342                       \n",
      "    94     2.094063   2.084276   0.367394                       \n",
      "    95     2.09474    2.083291   0.367842                       \n",
      "    96     2.100008   2.082713   0.367658                       \n",
      "    97     2.09403    2.098987   0.365416                       \n",
      "    98     2.088091   2.087335   0.366803                       \n",
      "    99     2.096852   2.080834   0.368181                       \n",
      "   100     2.098467   2.088123   0.367003                       \n",
      "   101     2.101503   2.090021   0.367419                       \n",
      "   102     2.099206   2.089548   0.366961                       \n",
      "   103     2.099916   2.087144   0.367321                       \n",
      "   104     2.100652   2.085183   0.367668                       \n",
      "   105     2.0986     2.084683   0.367855                       \n",
      "   106     2.082147   2.086492   0.366899                       \n",
      "   107     2.099307   2.092736   0.366523                       \n",
      "   108     2.095382   2.085611   0.367789                       \n",
      "   109     2.099494   2.090671   0.366467                       \n",
      "   110     2.096378   2.082262   0.367906                       \n",
      "   111     2.101298   2.085341   0.367611                       \n",
      "   112     2.098967   2.085133   0.367675                       \n",
      "   113     2.095079   2.082313   0.367509                       \n",
      "   114     2.093922   2.082737   0.367597                       \n",
      "   115     2.093051   2.083297   0.366812                       \n",
      "   116     2.092927   2.093216   0.365811                       \n",
      "   117     2.097992   2.079311   0.368488                       \n",
      "   118     2.096349   2.082094   0.36756                        \n",
      "   119     2.093705   2.086468   0.367112                       \n",
      "   120     2.097332   2.082321   0.367709                       \n",
      "   121     2.092112   2.086011   0.367874                       \n",
      "   122     2.10101    2.08288    0.367684                       \n",
      "   123     2.093125   2.08374    0.36711                        \n",
      "   124     2.09245    2.085295   0.367763                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   125     2.092742   2.086062   0.367444                       \n",
      "   126     2.102051   2.088527   0.367074                       \n",
      "   127     2.091475   2.085293   0.367427                       \n",
      "   128     2.093452   2.083246   0.367535                       \n",
      "   129     2.090811   2.083342   0.367589                       \n",
      "   130     2.085967   2.083727   0.367412                       \n",
      "   131     2.097909   2.078935   0.368024                       \n",
      "   132     2.095851   2.081774   0.367861                       \n",
      "   133     2.10232    2.086641   0.367372                       \n",
      "   134     2.097843   2.082095   0.367606                       \n",
      "   135     2.095465   2.087148   0.366689                       \n",
      "   136     2.094155   2.096195   0.365688                       \n",
      "   137     2.090105   2.085544   0.367508                       \n",
      "   138     2.09818    2.078413   0.368213                       \n",
      "   139     2.09794    2.084604   0.367164                       \n",
      "   140     2.084678   2.079154   0.368647                       \n",
      "   141     2.096159   2.07871    0.368471                       \n",
      "   142     2.0921     2.08452    0.367321                       \n",
      "   143     2.095955   2.079386   0.368244                       \n",
      "   144     2.091894   2.082904   0.36767                        \n",
      "   145     2.096397   2.078692   0.368313                       \n",
      "   146     2.093807   2.095407   0.365348                       \n",
      "   147     2.103961   2.08089    0.368189                       \n",
      "   148     2.097066   2.083943   0.366991                       \n",
      "   149     2.096243   2.085478   0.367839                       \n",
      "   150     2.0831     2.092197   0.365599                       \n",
      "   151     2.095457   2.079419   0.368404                       \n",
      "   152     2.089867   2.08446    0.367601                       \n",
      "   153     2.090738   2.082862   0.367567                       \n",
      "   154     2.089642   2.084155   0.367623                       \n",
      "   155     2.09234    2.082052   0.367837                       \n",
      "   156     2.101206   2.081894   0.367874                       \n",
      "   157     2.096686   2.087556   0.366663                       \n",
      "   158     2.086398   2.080749   0.367855                       \n",
      "   159     2.09935    2.084268   0.367454                       \n",
      "   160     2.099212   2.089846   0.36677                        \n",
      "   161     2.088418   2.086917   0.367075                       \n",
      "   162     2.087023   2.079885   0.368295                       \n",
      "   163     2.094966   2.079077   0.368065                       \n",
      "   164     2.101387   2.080416   0.367883                       \n",
      "   165     2.090999   2.078532   0.368596                       \n",
      "   166     2.09096    2.078417   0.368682                       \n",
      "   167     2.09374    2.084854   0.368167                       \n",
      "   168     2.096698   2.082694   0.368064                       \n",
      "   169     2.088883   2.078907   0.368197                       \n",
      "   170     2.091306   2.095456   0.365305                       \n",
      "   171     2.092477   2.080293   0.368608                       \n",
      "   172     2.09801    2.081006   0.368006                       \n",
      "   173     2.097006   2.08264    0.367961                       \n",
      "   174     2.089299   2.08172    0.367999                       \n",
      "   175     2.093518   2.079779   0.36834                        \n",
      "   176     2.087826   2.079724   0.368216                       \n",
      "   177     2.08993    2.084523   0.367807                       \n",
      "   178     2.088016   2.078656   0.368346                       \n",
      "   179     2.092232   2.081013   0.368409                       \n",
      "   180     2.094433   2.08036    0.368041                       \n",
      "   181     2.088384   2.079089   0.368414                       \n",
      "   182     2.099966   2.077674   0.368556                       \n",
      "   183     2.092292   2.079416   0.368185                       \n",
      "   184     2.094536   2.080548   0.36838                        \n",
      "   185     2.094903   2.077139   0.368204                       \n",
      "   186     2.096018   2.080867   0.368424                       \n",
      "   187     2.092939   2.085165   0.36726                        \n",
      "   188     2.097914   2.07694    0.36919                        \n",
      "   189     2.087496   2.079274   0.368539                       \n",
      "   190     2.092489   2.08297    0.3678                         \n",
      "   191     2.093607   2.082168   0.36795                        \n",
      "   192     2.088993   2.08488    0.367473                       \n",
      "   193     2.092187   2.080459   0.368565                       \n",
      "   194     2.094796   2.082385   0.36744                        \n",
      "   195     2.089403   2.08866    0.367521                       \n",
      "   196     2.098011   2.093942   0.366414                       \n",
      "   197     2.087056   2.084812   0.366856                       \n",
      "   198     2.087437   2.079896   0.36766                        \n",
      "   199     2.086467   2.084558   0.367173                       \n",
      "Validation accuracy:  36.717320311897716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184e23e000134718998156751a0c818e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      2.570693   2.562807   0.276942  \n",
      "    1      2.525522   2.512819   0.285962                       \n",
      "    2      2.493059   2.482409   0.290363                       \n",
      "    3      2.491524   2.486799   0.290317                       \n",
      "    4      2.481328   2.466924   0.292876                       \n",
      "    5      2.488222   2.486801   0.290872                       \n",
      "    6      2.473547   2.464014   0.293333                       \n",
      "    7      2.470779   2.470105   0.293132                       \n",
      "    8      2.473451   2.460844   0.294632                       \n",
      "    9      2.464983   2.462757   0.294254                       \n",
      "    10     2.470553   2.454601   0.295481                       \n",
      "    11     2.46747    2.454945   0.295405                       \n",
      "    12     2.46762    2.457988   0.295608                       \n",
      "    13     2.46015    2.457647   0.295645                       \n",
      "    14     2.465701   2.456487   0.295651                       \n",
      "    15     2.469614   2.453013   0.295611                       \n",
      "    16     2.463477   2.451061   0.295979                       \n",
      "    17     2.465967   2.450446   0.296259                       \n",
      "    18     2.462082   2.451444   0.295918                       \n",
      "    19     2.461999   2.450712   0.296273                       \n",
      "    20     2.466529   2.452379   0.296054                       \n",
      "    21     2.462851   2.445653   0.296961                       \n",
      "    22     2.457654   2.447626   0.296258                       \n",
      "    23     2.457938   2.45378    0.296289                       \n",
      "    24     2.461349   2.450049   0.296972                       \n",
      "    25     2.455557   2.449437   0.296569                       \n",
      "    26     2.452876   2.448291   0.296556                       \n",
      "    27     2.450986   2.452491   0.296605                       \n",
      "    28     2.456586   2.44494    0.297068                       \n",
      "    29     2.459535   2.44202    0.297658                       \n",
      "    30     2.45442    2.451828   0.295971                       \n",
      "    31     2.455583   2.4465     0.296454                       \n",
      "    32     2.461544   2.449321   0.297479                       \n",
      "    33     2.450853   2.444454   0.297414                       \n",
      "    34     2.45825    2.443838   0.297412                       \n",
      "    35     2.451713   2.444168   0.297446                       \n",
      "    36     2.455534   2.444319   0.297677                       \n",
      "    37     2.452674   2.444671   0.297729                       \n",
      "    38     2.458257   2.442965   0.29765                        \n",
      "    39     2.455741   2.445262   0.296859                       \n",
      "    40     2.46152    2.442634   0.29745                        \n",
      "    41     2.454637   2.438527   0.297679                       \n",
      "    42     2.452558   2.445509   0.296945                       \n",
      "    43     2.44888    2.444679   0.29704                        \n",
      "    44     2.450864   2.44083    0.297983                       \n",
      "    45     2.453418   2.440252   0.297654                       \n",
      "    46     2.449457   2.43894    0.297943                       \n",
      "    47     2.452134   2.438756   0.297865                       \n",
      "    48     2.449306   2.446407   0.297433                       \n",
      "    49     2.447501   2.448815   0.297405                       \n",
      "    50     2.454078   2.437844   0.29827                        \n",
      "    51     2.452289   2.438972   0.29839                        \n",
      "    52     2.454426   2.440242   0.297422                       \n",
      "    53     2.445819   2.449033   0.296337                       \n",
      "    54     2.453044   2.438822   0.298178                       \n",
      "    55     2.449699   2.439112   0.297042                       \n",
      "    56     2.455816   2.439089   0.297917                       \n",
      "    57     2.439723   2.43845    0.298288                       \n",
      "    58     2.444362   2.442227   0.29771                        \n",
      "    59     2.448155   2.437471   0.298233                       \n",
      "    60     2.452191   2.439293   0.298234                       \n",
      "    61     2.444752   2.436821   0.298802                       \n",
      "    62     2.442943   2.436646   0.298459                       \n",
      "    63     2.449093   2.435355   0.298585                       \n",
      "    64     2.445202   2.436282   0.298393                       \n",
      "    65     2.445678   2.43508    0.298659                       \n",
      "    66     2.442452   2.438516   0.298157                       \n",
      "    67     2.452001   2.438046   0.298319                       \n",
      "    68     2.450543   2.435494   0.298906                       \n",
      "    69     2.442491   2.440803   0.297827                       \n",
      "    70     2.443427   2.437537   0.298003                       \n",
      "    71     2.448138   2.439218   0.298627                       \n",
      "    72     2.445353   2.437101   0.298732                       \n",
      "    73     2.44038    2.434974   0.29852                        \n",
      "    74     2.447828   2.434384   0.29872                        \n",
      "    75     2.442082   2.438273   0.298553                       \n",
      "    76     2.442842   2.437855   0.298696                       \n",
      "    77     2.437744   2.435021   0.298603                       \n",
      "    78     2.441014   2.439063   0.298286                       \n",
      "    79     2.443303   2.433983   0.29849                        \n",
      "    80     2.440847   2.432372   0.299143                       \n",
      "    81     2.440436   2.438034   0.298853                       \n",
      "    82     2.441055   2.434194   0.298354                       \n",
      "    83     2.440733   2.438171   0.29833                        \n",
      "    84     2.446665   2.438569   0.298598                       \n",
      "    85     2.441846   2.433787   0.298283                       \n",
      "    86     2.443786   2.433487   0.299133                       \n",
      "    87     2.448059   2.435942   0.298847                       \n",
      "    88     2.43938    2.434181   0.298646                       \n",
      "    89     2.440009   2.434728   0.298669                       \n",
      "    90     2.439806   2.436256   0.298625                       \n",
      "    91     2.4452     2.43494    0.298527                       \n",
      "    92     2.44187    2.43086    0.298909                       \n",
      "    93     2.435836   2.432573   0.299005                       \n",
      "    94     2.435253   2.432431   0.298875                       \n",
      "    95     2.447662   2.431942   0.298741                       \n",
      "    96     2.442862   2.435441   0.298008                       \n",
      "    97     2.441671   2.43221    0.299097                       \n",
      "    98     2.440849   2.43125    0.299104                       \n",
      "    99     2.437963   2.438678   0.297981                       \n",
      "   100     2.442285   2.432351   0.29916                        \n",
      "   101     2.441235   2.430406   0.29913                        \n",
      "   102     2.456269   2.429427   0.299159                       \n",
      "   103     2.450138   2.43621    0.298799                       \n",
      "   104     2.441856   2.440462   0.298443                       \n",
      "   105     2.438812   2.43091    0.298841                       \n",
      "   106     2.444813   2.439901   0.298384                       \n",
      "   107     2.435225   2.436845   0.298834                       \n",
      "   108     2.43345    2.430438   0.299032                       \n",
      "   109     2.440218   2.433188   0.29907                        \n",
      "   110     2.432928   2.429333   0.298491                       \n",
      "   111     2.43597    2.436813   0.298089                       \n",
      "   112     2.448652   2.43153    0.29906                        \n",
      "   113     2.447661   2.433453   0.298468                       \n",
      "   114     2.444029   2.435048   0.298366                       \n",
      "   115     2.432732   2.430115   0.298429                       \n",
      "   116     2.447832   2.43631    0.298841                       \n",
      "   117     2.444082   2.437369   0.298575                       \n",
      "   118     2.437486   2.435848   0.298532                       \n",
      "   119     2.444918   2.428087   0.298876                       \n",
      "   120     2.442532   2.427885   0.298986                       \n",
      "   121     2.442612   2.43358    0.298645                       \n",
      "   122     2.448639   2.434557   0.298509                       \n",
      "   123     2.435412   2.425719   0.299117                       \n",
      "   124     2.436269   2.432823   0.299214                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   125     2.435239   2.434565   0.298108                       \n",
      "   126     2.45031    2.437684   0.297829                       \n",
      "   127     2.438909   2.428932   0.298805                       \n",
      "   128     2.430963   2.43187    0.299002                       \n",
      "   129     2.429436   2.427741   0.299032                       \n",
      "   130     2.437585   2.433655   0.298491                       \n",
      "   131     2.431628   2.429661   0.299164                       \n",
      "   132     2.433672   2.432001   0.298909                       \n",
      "   133     2.441541   2.427646   0.299186                       \n",
      "   134     2.433734   2.430974   0.29907                        \n",
      "   135     2.439417   2.429668   0.298884                       \n",
      "   136     2.435925   2.432282   0.298814                       \n",
      "   137     2.436406   2.431784   0.298271                       \n",
      "   138     2.437583   2.429596   0.298754                       \n",
      "   139     2.449282   2.426179   0.299469                       \n",
      "   140     2.433646   2.423829   0.299337                       \n",
      "   141     2.435667   2.428953   0.29926                        \n",
      "   142     2.437105   2.428378   0.298811                       \n",
      "   143     2.434253   2.424859   0.299424                       \n",
      "   144     2.42355    2.425527   0.299403                       \n",
      "   145     2.432603   2.436894   0.298163                       \n",
      "   146     2.432376   2.442154   0.297712                       \n",
      "   147     2.436177   2.43004    0.298531                       \n",
      "   148     2.44297    2.423861   0.299167                       \n",
      "   149     2.438859   2.431179   0.299055                       \n",
      "   150     2.435327   2.440458   0.298466                       \n",
      "   151     2.442618   2.428443   0.299197                       \n",
      "   152     2.433935   2.429246   0.298911                       \n",
      "   153     2.443507   2.424175   0.299237                       \n",
      "   154     2.432336   2.420162   0.299668                       \n",
      "   155     2.430624   2.427191   0.29894                        \n",
      "   156     2.437988   2.427952   0.299053                       \n",
      "   157     2.430381   2.421693   0.299609                       \n",
      "   158     2.436361   2.430107   0.299049                       \n",
      "   159     2.435029   2.432884   0.298644                       \n",
      "   160     2.437323   2.437016   0.298673                       \n",
      "   161     2.438067   2.424221   0.298743                       \n",
      "   162     2.436663   2.425349   0.299451                       \n",
      "   163     2.438054   2.429137   0.298844                       \n",
      "   164     2.436584   2.423877   0.299054                       \n",
      "   165     2.438769   2.420503   0.299399                       \n",
      "   166     2.434161   2.424274   0.299258                       \n",
      "   167     2.43583    2.432326   0.298954                       \n",
      "   168     2.432609   2.4371     0.298537                       \n",
      "   169     2.442001   2.425234   0.298982                       \n",
      "   170     2.435433   2.431907   0.298303                       \n",
      "   171     2.43918    2.42542    0.299105                       \n",
      "   172     2.43505    2.429386   0.298511                       \n",
      "   173     2.436048   2.43082    0.29874                        \n",
      "   174     2.430641   2.423192   0.298976                       \n",
      "   175     2.438684   2.425283   0.299333                       \n",
      "   176     2.423076   2.423591   0.29946                        \n",
      "   177     2.432355   2.42736    0.29941                        \n",
      "   178     2.428144   2.422994   0.29912                        \n",
      "   179     2.438826   2.428802   0.298996                       \n",
      "   180     2.436547   2.42413    0.299014                       \n",
      "   181     2.43577    2.420095   0.299777                       \n",
      "   182     2.430622   2.430457   0.299415                       \n",
      "   183     2.435258   2.422438   0.299191                       \n",
      "   184     2.426489   2.421322   0.299564                       \n",
      "   185     2.435312   2.428303   0.298911                       \n",
      "   186     2.431358   2.427264   0.299326                       \n",
      "   187     2.438397   2.427003   0.298746                       \n",
      "   188     2.434498   2.431161   0.299173                       \n",
      "   189     2.437752   2.424288   0.299356                       \n",
      "   190     2.440183   2.427634   0.299195                       \n",
      "   191     2.439483   2.432711   0.298708                       \n",
      "   192     2.434822   2.4229     0.299709                       \n",
      "   193     2.426609   2.42685    0.298918                       \n",
      "   194     2.433399   2.424639   0.299263                       \n",
      "   195     2.426997   2.425859   0.299203                       \n",
      "   196     2.431572   2.423661   0.299409                       \n",
      "   197     2.422203   2.42199    0.299457                       \n",
      "   198     2.431291   2.42201    0.299805                       \n",
      "   199     2.428356   2.428038   0.299494                       \n",
      "Validation accuracy:  29.94936782213648\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1ce7665d9a46679e419e2e518f29c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      2.921371   2.90938    0.21605   \n",
      "    1      2.89987    2.88796    0.219401                       \n",
      "    2      2.888316   2.874784   0.220918                       \n",
      "    3      2.879358   2.871067   0.221197                       \n",
      "    4      2.867778   2.863665   0.221997                       \n",
      "    5      2.86415    2.861782   0.222187                       \n",
      "    6      2.864426   2.863383   0.222658                       \n",
      "    7      2.86471    2.851541   0.222756                       \n",
      "    8      2.860923   2.848922   0.223135                       \n",
      "    9      2.851355   2.851696   0.223183                       \n",
      "    10     2.849987   2.84718    0.22356                        \n",
      "    11     2.839358   2.837114   0.223712                       \n",
      "    12     2.846703   2.854068   0.223194                       \n",
      "    13     2.852611   2.854936   0.223352                       \n",
      "    14     2.843646   2.843774   0.223678                       \n",
      "    15     2.844705   2.833836   0.224191                       \n",
      "    16     2.853907   2.837075   0.22389                        \n",
      "    17     2.843995   2.832416   0.224075                       \n",
      "    18     2.84205    2.838437   0.224011                       \n",
      "    19     2.845074   2.848758   0.224153                       \n",
      "    20     2.839151   2.839176   0.224282                       \n",
      "    21     2.832817   2.836158   0.224072                       \n",
      "    22     2.842778   2.850503   0.223596                       \n",
      "    23     2.842032   2.830306   0.224485                       \n",
      "    24     2.837085   2.825469   0.224604                       \n",
      "    25     2.842191   2.833928   0.224421                       \n",
      "    26     2.840409   2.882343   0.224335                       \n",
      "    27     2.834346   2.826261   0.224672                       \n",
      "    28     2.833885   2.846598   0.223767                       \n",
      "    29     2.833644   2.832909   0.224379                       \n",
      "    30     2.83147    2.825096   0.224279                       \n",
      "    31     2.837802   2.832784   0.224409                       \n",
      "    32     2.830442   2.821538   0.225158                       \n",
      "    33     2.833241   2.823849   0.224821                       \n",
      "    34     2.837391   2.82285    0.224893                       \n",
      "    35     2.830216   2.841282   0.224656                       \n",
      "    36     2.827828   2.823802   0.225333                       \n",
      "    37     2.840243   2.833797   0.224812                       \n",
      "    38     2.827168   2.813623   0.225204                       \n",
      "    39     2.835925   2.824806   0.225012                       \n",
      "    40     2.831438   2.822252   0.224789                       \n",
      "    41     2.845261   2.839395   0.223817                       \n",
      "    42     2.834231   2.822176   0.225213                       \n",
      "    43     2.827814   2.819299   0.225227                       \n",
      "    44     2.822273   2.824834   0.225237                       \n",
      "    45     2.825942   2.820797   0.224875                       \n",
      "    46     2.842717   2.823317   0.224953                       \n",
      "    47     2.83083    2.812416   0.225363                       \n",
      "    48     2.830517   2.811705   0.224879                       \n",
      "    49     2.827601   2.82952    0.225045                       \n",
      "    50     2.83414    2.821769   0.225215                       \n",
      "    51     2.822746   2.818374   0.225418                       \n",
      "    52     2.826736   2.837965   0.224712                       \n",
      "    53     2.827131   2.839445   0.225064                       \n",
      "    54     2.83059    2.808242   0.225346                       \n",
      "    55     2.834535   2.819641   0.225391                       \n",
      "    56     2.83164    2.808205   0.225483                       \n",
      "    57     2.826174   2.831952   0.225301                       \n",
      "    58     2.826447   2.836938   0.225143                       \n",
      "    59     2.827317   2.833037   0.225372                       \n",
      "    60     2.823162   2.83576    0.225433                       \n",
      "    61     2.828313   2.827715   0.225223                       \n",
      "    62     2.824449   2.822001   0.225628                       \n",
      "    63     2.817685   2.85669    0.224563                       \n",
      "    64     2.824427   2.829474   0.225603                       \n",
      "    65     2.828367   2.821441   0.225282                       \n",
      "    66     2.831267   2.820307   0.224935                       \n",
      "    67     2.817842   2.824961   0.225103                       \n",
      "    68     2.826593   2.819265   0.225598                       \n",
      "    69     2.813668   2.827861   0.225121                       \n",
      "    70     2.830997   2.814799   0.225308                       \n",
      "    71     2.823636   2.810319   0.22567                        \n",
      "    72     2.829062   2.824684   0.225464                       \n",
      "    73     2.82391    2.809435   0.225667                       \n",
      "    74     2.832668   2.830848   0.224939                       \n",
      "    75     2.822264   2.818687   0.22549                        \n",
      "    76     2.828434   2.816046   0.225029                       \n",
      "    77     2.825396   2.843235   0.22487                        \n",
      "    78     2.823485   2.824107   0.225232                       \n",
      "    79     2.819971   2.810061   0.225878                       \n",
      "    80     2.814891   2.812066   0.225885                       \n",
      "    81     2.825668   2.832279   0.225242                       \n",
      "    82     2.819716   2.838153   0.225249                       \n",
      "    83     2.827719   2.818642   0.225611                       \n",
      "    84     2.825085   2.812527   0.225724                       \n",
      "    85     2.821688   2.814879   0.225758                       \n",
      "    86     2.824939   2.81033    0.226202                       \n",
      "    87     2.823173   2.814465   0.225845                       \n",
      "    88     2.822054   2.81047    0.225948                       \n",
      "    89     2.828056   2.836257   0.225248                       \n",
      "    90     2.822444   2.815598   0.225976                       \n",
      "    91     2.822715   2.804245   0.225844                       \n",
      "    92     2.820271   2.8243     0.224822                       \n",
      "    93     2.818376   2.826769   0.225775                       \n",
      "    94     2.821652   2.807853   0.225721                       \n",
      "    95     2.809612   2.821414   0.225885                       \n",
      "    96     2.82149    2.810069   0.225924                       \n",
      "    97     2.8125     2.819434   0.226029                       \n",
      "    98     2.80244    2.808334   0.226118                       \n",
      "    99     2.817964   2.806287   0.226081                       \n",
      "   100     2.825566   2.805583   0.225817                       \n",
      "   101     2.8232     2.818913   0.225613                       \n",
      "   102     2.816032   2.811174   0.226074                       \n",
      "   103     2.818391   2.811232   0.225755                       \n",
      "   104     2.814675   2.812034   0.226203                       \n",
      "   105     2.809834   2.802884   0.2264                         \n",
      "   106     2.827702   2.815554   0.226044                       \n",
      "   107     2.815319   2.803526   0.226281                       \n",
      "   108     2.818756   2.80977    0.225904                       \n",
      "   109     2.821142   2.815707   0.225827                       \n",
      "   110     2.823457   2.808315   0.226185                       \n",
      "   111     2.807248   2.811757   0.226324                       \n",
      "   112     2.809679   2.800891   0.226272                       \n",
      "   113     2.828414   2.818505   0.225866                       \n",
      "   114     2.811767   2.800697   0.226328                       \n",
      "   115     2.814745   2.803472   0.225799                       \n",
      "   116     2.818303   2.826102   0.22557                        \n",
      "   117     2.819556   2.803193   0.226337                       \n",
      "   118     2.816477   2.827066   0.226095                       \n",
      "   119     2.811079   2.80155    0.226279                       \n",
      "   120     2.809567   2.81103    0.226109                       \n",
      "   121     2.816939   2.820079   0.226217                       \n",
      "   122     2.823195   2.819932   0.226229                       \n",
      "   123     2.808793   2.804295   0.226272                       \n",
      "   124     2.820038   2.8197     0.225557                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   125     2.806025   2.800443   0.22647                        \n",
      "   126     2.81129    2.819079   0.226275                       \n",
      "   127     2.813928   2.837695   0.226261                       \n",
      "   128     2.809255   2.800726   0.226199                       \n",
      "   129     2.808087   2.814727   0.226441                       \n",
      "   130     2.809284   2.799692   0.226157                       \n",
      "   131     2.81574    2.810567   0.226219                       \n",
      "   132     2.817174   2.812699   0.226015                       \n",
      "   133     2.813151   2.799576   0.226267                       \n",
      "   134     2.815861   2.806706   0.22579                        \n",
      "   135     2.824954   2.809991   0.226284                       \n",
      "   136     2.813512   2.812057   0.226329                       \n",
      "   137     2.815652   2.802042   0.226272                       \n",
      "   138     2.817436   2.800607   0.226354                       \n",
      "   139     2.818641   2.814589   0.225965                       \n",
      "   140     2.809617   2.813549   0.226172                       \n",
      "   141     2.816118   2.813403   0.226105                       \n",
      "   142     2.800328   2.811911   0.226182                       \n",
      "   143     2.822845   2.823547   0.2259                         \n",
      "   144     2.81285    2.820545   0.226114                       \n",
      "   145     2.809733   2.812214   0.226526                       \n",
      "   146     2.818559   2.810191   0.226306                       \n",
      "   147     2.802071   2.799244   0.226416                       \n",
      "   148     2.809369   2.802096   0.226184                       \n",
      "   149     2.815568   2.812907   0.226371                       \n",
      "   150     2.813175   2.808186   0.226528                       \n",
      "   151     2.812229   2.809104   0.226155                       \n",
      "   152     2.808566   2.822888   0.226306                       \n",
      "   153     2.816494   2.79975    0.226513                       \n",
      "   154     2.804773   2.814661   0.226273                       \n",
      "   155     2.80247    2.799188   0.226419                       \n",
      "   156     2.812763   2.798522   0.226405                       \n",
      "   157     2.809728   2.804125   0.226071                       \n",
      "   158     2.812205   2.815814   0.226318                       \n",
      "   159     2.809622   2.810797   0.226054                       \n",
      "   160     2.814746   2.837152   0.226533                       \n",
      "   161     2.806309   2.807204   0.226263                       \n",
      "   162     2.813036   2.801923   0.226145                       \n",
      "   163     2.807058   2.810861   0.226335                       \n",
      "   164     2.808613   2.802556   0.226449                       \n",
      "   165     2.812503   2.797352   0.226347                       \n",
      "   166     2.812278   2.803916   0.226603                       \n",
      "   167     2.802185   2.798793   0.226542                       \n",
      "   168     2.804902   2.798715   0.226474                       \n",
      "   169     2.804678   2.794191   0.226411                       \n",
      "   170     2.811021   2.813732   0.226264                       \n",
      "   171     2.809718   2.797938   0.226417                       \n",
      "   172     2.815723   2.804965   0.226264                       \n",
      "   173     2.823837   2.805205   0.226356                       \n",
      "   174     2.819908   2.809662   0.22626                        \n",
      "   175     2.817303   2.82202    0.226246                       \n",
      "   176     2.805944   2.800867   0.226479                       \n",
      "   177     2.804285   2.794226   0.226366                       \n",
      "   178     2.80509    2.8015     0.226725                       \n",
      "   179     2.807004   2.800721   0.2266                         \n",
      "   180     2.822779   2.801636   0.225977                       \n",
      "   181     2.809618   2.807014   0.226489                       \n",
      "   182     2.805652   2.796718   0.226351                       \n",
      "   183     2.803168   2.809383   0.226369                       \n",
      "   184     2.808076   2.8021     0.226542                       \n",
      "   185     2.811274   2.815741   0.225907                       \n",
      "   186     2.811389   2.836082   0.225465                       \n",
      "   187     2.80578    2.801448   0.226521                       \n",
      "   188     2.808106   2.816879   0.226438                       \n",
      "   189     2.815111   2.794978   0.2265                         \n",
      "   190     2.81578    2.809497   0.226114                       \n",
      "   191     2.811077   2.79806    0.226767                       \n",
      "   192     2.800412   2.800079   0.226345                       \n",
      "   193     2.813891   2.806592   0.226519                       \n",
      "   194     2.80629    2.826601   0.226176                       \n",
      "   195     2.815708   2.810974   0.226379                       \n",
      "   196     2.811044   2.798578   0.226492                       \n",
      "   197     2.812961   2.797538   0.226537                       \n",
      "   198     2.806571   2.800004   0.226445                       \n",
      "   199     2.805759   2.80322    0.226135                       \n",
      "Validation accuracy:  22.6135194091792\n"
     ]
    }
   ],
   "source": [
    "for QP in [27, 32, 37]:\n",
    "    if 'df' in globals(): del df, y, mapper\n",
    "    df, y, mapper, emb_szs, val_idx = read_proc()\n",
    "    export_mapper()\n",
    "    md = ColumnarModelData.from_data_frame(INP, val_idx, df, y, cat_flds=cat_vars, \n",
    "                                           bs=1024, is_multi=False, is_reg=False)\n",
    "    m = md.get_learner(emb_szs, len(df.columns) - len(cat_vars),\n",
    "                       0.001, 49, Layers, Dropouts, use_bn=BN_use)\n",
    "    m.fit(LR, 200, metrics=[accuracy])\n",
    "    save_model()\n",
    "    export_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
